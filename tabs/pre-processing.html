<div class="content-section research-pipeline">
  <h1>SPROUT Pre-Processing Research Pipeline</h1>
  <p>This page documents the end-to-end audio pre-processing pipeline developed for the SPROUT pediatric speech dataset. Each raw recording is processed through three stages—<strong>Denoising</strong>, <strong>Pre-Processing Quality Control (Pre-QC)</strong>, and <strong>Post-Processing Quality Control (Post-QC)</strong>—to produce clean, uniform, and research-ready audio suitable for diarization, transcription, and feature extraction.</p>

  <!-- 1. Denoising -->
  <section id="denoising" class="subsection">
    <h2>1. Denoising</h2>
    <p>The primary goal of denoising is to attenuate environmental and electronic noise while preserving the spectral integrity of child speech signals.</p>

    <h3>Tools &amp; Algorithms</h3>
    <ul>
      <li><strong>librosa</strong> – loading, resampling, STFT/iSTFT</li>
      <li><strong>noisereduce</strong> – spectral gating (Wiener), <code>nr.reduce_noise()</code></li>
      <li><strong>soundfile</strong> – high-precision WAV I/O</li>
      <li><strong>pyloudnorm</strong> – ITU-R BS.1770-4 measurement & normalization to –16 LUFS</li>
      <li><strong>numpy</strong>, <strong>pandas</strong>, <strong>psutil</strong> – array ops, logging, memory monitoring</li>
    </ul>

    <h3>Pipeline Steps</h3>
    <ol>
      <li>Load raw audio: <code>y, sr = librosa.load(path, sr=None)</code></li>
      <li>Estimate noise profile from low-energy frames</li>
      <li>Apply spectral gating: <code>clean = nr.reduce_noise(y, sr, prop_decrease=1.0)</code></li>
      <li>Clip to ±1: <code>clean = np.clip(clean, -1.0, 1.0)</code></li>
      <li>Normalize loudness: <code>pyln.normalize.loudness(clean, meter.integrated_loudness(clean), -16.0)</code></li>
      <li>Save: <code>sf.write(out_path, clean_norm, sr, subtype='PCM_24')</code></li>
      <li>Log duration, memory, status → CSV</li>
    </ol>

    <details class="code-details">
      <summary>View denoising code snippet</summary>
      <button class="copy-btn">Copy</button>
      <pre><code>import librosa
import noisereduce as nr
import numpy as np
import soundfile as sf
import pyloudnorm as pyln

y, sr = librosa.load("input.wav", sr=None)
clean = nr.reduce_noise(y=y, sr=sr, prop_decrease=1.0, stationary=False)
clean = np.clip(clean, -1.0, 1.0)

meter = pyln.Meter(sr)
clean_norm = pyln.normalize.loudness(clean,
    meter.integrated_loudness(clean), -16.0)

sf.write("output_nr.wav", clean_norm, sr, subtype='PCM_24')</code></pre>
    </details>
  </section>

  <!-- 2. Pre-QC -->
  <section id="pre-qc" class="subsection">
    <h2>2. Pre-Processing Quality Control (Pre-QC)</h2>
    <p>Pre-QC evaluates whether denoised audio meets minimal acoustic standards before expensive downstream processing.</p>

    <input type="text" id="preqcFilter" class="table-filter" placeholder="Filter features…" />

    <table id="preqcTable">
      <thead>
        <tr><th>Feature</th><th>Description</th><th>Threshold</th></tr>
      </thead>
      <tbody>
        <tr><td>Duration (s)</td><td>Total samples ÷ sr</td><td>> 1.0</td></tr>
        <tr><td>SNR (dB)</td><td>10 log₁₀(P_signal/P_noise)</td><td>> 15</td></tr>
        <tr><td>Spectral Centroid (Hz)</td><td>Brightness of spectrum</td><td>> 1000</td></tr>
        <tr><td>Spectral Bandwidth (Hz)</td><td>Spread of frequencies</td><td>> 1000</td></tr>
        <tr><td>Pitch Mean (Hz)</td><td>Average f₀ via YIN</td><td>> 250</td></tr>
      </tbody>
    </table>

    <details class="code-details">
      <summary>View Pre-QC code snippet</summary>
      <button class="copy-btn">Copy</button>
      <pre><code>import numpy as np

def compute_snr(y):
    signal_power = np.mean(y**2)
    frame_len, hop = 2048, 512
    energies = [np.sum(y[i:i+frame_len]**2)
                for i in range(0, len(y)-frame_len, hop)]
    noise_power = np.percentile(energies, 10)
    return 10 * np.log10(signal_power / noise_power)

snr = compute_snr(audio)
duration = len(audio) / sr
clipping = 100 * np.mean(np.abs(audio) >= 0.999)</code></pre>
    </details>
  </section>

  <!-- 3. Post-QC -->
  <section id="post-qc" class="subsection">
    <h2>3. Post-Processing Quality Control (Post-QC)</h2>
    <p>Post-QC performs a final, comprehensive evaluation to flag any remaining issues and confirm research readiness.</p>

    <input type="text" id="postqcFilter" class="table-filter" placeholder="Filter features…" />

    <table id="postqcTable">
      <thead>
        <tr><th>Feature</th><th>Range</th></tr>
      </thead>
      <tbody>
        <tr><td>Signal Energy</td><td>1e-6 … 1e-1</td></tr>
        <tr><td>SPL (dB)</td><td>39 … 70</td></tr>
        <tr><td>LUFS</td><td>No hard limit</td></tr>
        <tr><td>RMS</td><td>1e-5 … 0.21</td></tr>
        <tr><td>Spectral Centroid</td><td>900 … 5000</td></tr>
        <tr><td>Pitch Mean</td><td>250 … 400</td></tr>
        <tr><td>MFCC Mean</td><td>–40 … 40</td></tr>
      </tbody>
    </table>

    <details class="code-details">
      <summary>View Post-QC code snippet</summary>
      <button class="copy-btn">Copy</button>
      <pre><code>import soundfile as sf
import librosa
import pyloudnorm as pyln

audio, sr = sf.read("output_nr.wav")
audio = librosa.resample(audio, sr, 16000)

meter = pyln.Meter(16000)
lufs = meter.integrated_loudness(audio)

centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=16000))
pitch = np.mean(librosa.yin(audio, 250, 400))

# assemble into DataFrame & export CSV
</code></pre>
    </details>
  </section>
</div>

<style>
  .content-section { padding: 2rem; background: #fff; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); margin-bottom: 2rem; }
  .research-pipeline h1 { font-family: Montserrat, sans-serif; color: #4E2A84; margin-bottom: 1rem; }
  .subsection { margin-top: 2rem; }
  .subsection h2 { font-family: Montserrat, sans-serif; color: #4E2A84; margin-bottom: 0.5rem; }
  .subsection h3 { font-family: Montserrat, sans-serif; color: #FFD100; margin-top: 1rem; }
  .table-filter { width: 100%; max-width: 400px; padding: 0.5rem; margin: 0.5rem 0 1rem; border: 1px solid #ccc; border-radius: 4px; }
  table { width: 100%; border-collapse: collapse; margin-bottom: 1rem; }
  th, td { border: 1px solid #F0F9FA; padding: 0.75rem; text-align: left; }
  th { background: #F0F9FA; }
  details.code-details { margin-top: 1rem; }
  summary { cursor: pointer; font-weight: bold; }
  .copy-btn { float: right; margin: -1.5rem 0.5rem 0 0; padding: 0.2rem 0.5rem; background: #4E2A84; color: #fff; border: none; border-radius: 4px; cursor: pointer; }
  pre { background: #F5F5F5; padding: 1rem; overflow-x: auto; border-radius: 4px; }
</style>

<script>
  // Copy-to-clipboard
  document.querySelectorAll('.copy-btn').forEach(btn => {
    btn.addEventListener('click', () => {
      const code = btn.nextElementSibling.innerText;
      navigator.clipboard.writeText(code);
      btn.textContent = 'Copied!';
      setTimeout(() => btn.textContent = 'Copy', 2000);
    });
  });

  // Table filtering
  function setupFilter(inputId, tableId) {
    const input = document.getElementById(inputId);
    const table = document.getElementById(tableId).getElementsByTagName('tbody')[0];
    input.addEventListener('input', () => {
      const filter = input.value.toLowerCase();
      Array.from(table.rows).forEach(row => {
        const text = row.cells[0].innerText.toLowerCase();
        row.style.display = text.includes(filter) ? '' : 'none';
      });
    });
  }
  setupFilter('preqcFilter', 'preqcTable');
  setupFilter('postqcFilter', 'postqcTable');
</script>
