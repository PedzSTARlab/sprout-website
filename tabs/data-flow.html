<h2>SPROUT Data Processing Flow</h2>
<hr>

<div class="content-section">
    <h3>1. Data Collection</h3>
    <ul>
        <li>Multi-site collection across 8 U.S. cities: St. Louis (MO), Los Angeles (CA), Dallas (TX), Orlando (FL), Atlanta (GA), Baltimore (MD), Chicago (IL), and Iselin (NJ)</li>
        <li>Recording tools: Adobe Audition (<code>.wav</code>), Zoom (<code>.m4a</code>/<code>.mp4</code>)</li>
    </ul>

    <h3>2. File Organization & Metadata</h3>
    <ul>
        <li>BIDS-inspired directory structure implementation</li>
        <li>Compilation of <code>participants.tsv</code> file with demographic and clinical metadata</li>
    </ul>

    <h3>3. Pre-processing Pipeline</h3>
    <ul>
        <li><strong>Pre-QC:</strong> Automated assessment against minimal acoustic standards (SNR, clipping, duration)</li>
        <li><strong>Denoising:</strong> Environmental and microphone noise reduction while preserving speech integrity</li>
        <li><strong>Normalization:</strong> Audio level normalization and silence trimming</li>
    </ul>

    <h3>4. Post-processing Quality Assessment</h3>
    <ul>
        <li>Advanced acoustic feature evaluation for residual quality issues post denoising and normalization</li>
        <li>Eligibility determination for research use based on quality thresholds</li>
    </ul>

    <h3>5. Dataset Packaging & Distribution</h3>
    <ul>
        <li>Packaging data into tiered-access structure with proper consent management</li>
        <li>Creating dataset documentation and metadata files</li>
        <li>Applying appropriate data governance and access controls</li>
    </ul>

    <h3>6. Speaker Diarization & Segmentation</h3>
    <ul>
        <li>Experimentation for accurate speaker diarization (e.g., few-shot learning, cluster analysis for model tuning, etc.)</li>
        <li>Extracting child-only audio segments from multi-speaker recordings</li>
    </ul>

    <h3>7. Feature Extraction & Annotation</h3>
    <ul>
        <li>Automated acoustic feature extraction (MFCC, prosody, spectral features)</li>
        <li>Storing processed artifacts in version-controlled feature repository</li>
        <li>Generating phenotype files for clinical assessments</li>
    </ul>

    <h3>8. Automatic Speech Recognition (ASR)</h3>
    <ul>
        <li>Applying state-of-the-art open-source ASR models to child-only segments</li>
        <li>Research & experimentations for improved ASR accuracy for child speech</li>
        <li>Exploring bias identification and mitigation strategies in ASR outputs</li>
    </ul>
</div>

<h2>Data Flow Diagram</h2>

<div class="diagram-container">
    <img src="images/data-flow.png" alt="SPROUT Data Processing Flow Diagram" class="data-flow-image"/>
</div>

<style>
    .content-section {
        margin: 2rem 0;
    }
    
    .diagram-container {
        margin: 2rem 0;
        padding: 1rem;
        background-color: #f8f9fa;
        border-radius: 8px;
        text-align: center;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        width: 100%;
    }
    
    .data-flow-image {
        max-width: 100%;
        width: auto;
        height: auto;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        margin: 0 auto;
        display: block;
    }
</style>
